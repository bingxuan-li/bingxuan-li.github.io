<!DOCTYPE HTML>
<html lang="en">

<!-- head -->
<head>
  <script>
    (function () {
        var a_idx = 0;
        window.onclick = function (event) {
            var a = new Array("‚ú®", "ü§ñ", "ü•≥", "üëã", "ü¶æ", "üêΩ");

            var heart = document.createElement("b");
            heart.onselectstart = new Function('event.returnValue=false');

            document.body.appendChild(heart).innerHTML = a[a_idx];
            a_idx = (a_idx + 1) % a.length;
            heart.style.cssText = "position: fixed;left:-100%;";

            var f = 16, 
                x = event.clientX - f / 2, 
                y = event.clientY - f,
                c = randomColor(), 
                a = 1,
                s = 1.2; 

            var timer = setInterval(function () { 
                if (a <= 0) {
                    document.body.removeChild(heart);
                    clearInterval(timer);
                } else {
                    heart.style.cssText = "font-size:16px;cursor: default;position: fixed;color:" +
                        c + ";left:" + x + "px;top:" + y + "px;opacity:" + a + ";transform:scale(" +
                        s + ");";

                    y--;
                    a -= 0.016;
                    s += 0.002;
                }
            }, 15)

        }
        function randomColor() {

            return "rgb(" + (~~(Math.random() * 255)) + "," + (~~(Math.random() * 255)) + "," + (~~(Math
            .random() * 255)) + ")";

        }
    }());
  </script>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-66DNLPJ6PY"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-66DNLPJ6PY');
  </script>

  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Bingxuan Li   |  ÊùéÁßâËΩ©</title>
  
  <meta name="author" content="Haoran Geng">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" type="image/png" href="images/icon.png">

  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <meta name="author" content="Bingxuan Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">

</head>

<!-- bib hide -->
<script type="text/javascript">
  function hideshow(which){
  if (!document.getElementById)
  return
  if (which.style.display=="block")
  which.style.display="none"
  else
  which.style.display="block"
  }
</script>

<!-- body -->
<body>
  <!-- self-intro -->
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;line-height:1.5;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2%;width:55%;vertical-align:middle">
              <p style="text-align:center">
                <name>Bingxuan Li | ÊùéÁßâËΩ©</name>
              </p>

              <p style="text-align: justify">
              <intro>
                <p>
                  Hi! I am a second-year Computer Science Ph.D. candidate at NYU, 
                  advised by 
                  Prof. <a href="https://engineering.nyu.edu/faculty/qi-sun" target="_blank">Qi Sun</a> 
                  in the 
                  <a href="https://www.immersivecomputinglab.org/">Immersive Computing Lab</a>. 
                </p>
                <p>
                  My research interests are at the intersection of deep learning and computer graphics, 
                  focusing on <strong>3D understanding, reconstruction, and generation</strong>. 
                  Recently, I have been working on <strong>physics-informed monocular depth estimation</strong>, 
                  pushing toward a better trade-off between size and accuracy in depth cameras. 
                  My goal is to enable compact and power-efficient depth sensing for size-sensitive scenarios 
                  such as AR glasses, small robotics, mobile devices, and wearable systems.
                </p>
                <p>
                  Prior to NYU, I received my Bachelor's degree with honors from 
                  <a href="https://cfcs.pku.edu.cn/english/research/turing_program/introduction1/index.htm" target="_blank">
                   <d>Turing Class</d>
                  </a>, 
                  <a href="https://english.pku.edu.cn/" target="_blank">
                    <d>Peking University</d>
                  </a>. 
                 During my undergraduate years, I was honored to be advised by 
                 Prof. <a href="https://lishengpku.github.io/" target="_blank">Sheng Li</a> and 
                 Prof. <a href="https://sites.cs.ucsb.edu/~lingqi/" target="_blank"><d>Lingqi Yan</d></a>. 
                </p>
                <!-- <p style="font-size: 1.1em; color: red;">
                  <em>I am actively seeking a research internship for Summer 2026!</em>
                </p> -->

              </intro>
              <p style="text-align:center">
                <a href="mailto:bingxuan.li@nyu.edu" target="_blank"> Email </a> &nbsp/&nbsp
                <a href="https://github.com/bingxuan-li" target="_blank"> Github </a>&nbsp/&nbsp
                <a href="pdf/CV_Bingxuan.pdf" target="_blank"> CV </a>&nbsp/&nbsp
                <a href="https://www.linkedin.com/in/bingxuan-li-b71491330/" target="_blank"> LinkedIn </a>&nbsp/&nbsp
                <a href="images/wechat.jpg" target="_blank"> WeChat </a></a>&nbsp
              </p>
            </td>

            <td style="padding:0%; width:26%; max-width:26%;"> <!-- move the photo a bit left -->
              <br>
              <!-- <br> -->
              <img style="padding:1%; width:100%; max-width:80%;  display: block; margin-left: auto; margin-right: auto; " alt="profile photo" src="images/personal-cropped.jpg" class="hoverZoomLink">
              <!-- <a href="https://hits.seeyoufarm.com" target="_blank">
                <img 
                  src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2Fbingxuan-li&count_bg=%23ED7E21&title_bg=%23555555&icon=pluscodes.svg&icon_color=%23E7E7E7&title=hits&edge_flat=false"
                  style="display: block; margin-left: auto; margin-right: auto; width: 42%;"/>
              </a> -->
            </td>
            <!-- <td style="padding:5%;width:37%;max-width:37%"> 
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/face3.jpg" class="hoverZoomLink">
              <a href="https://hits.seeyoufarm.com" target="_blank"><img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgeng-haoran.github.io&count_bg=%23FF8400&title_bg=%23545353&icon=tableau.svg&icon_color=%23F3F209&title=hits&edge_flat=false"/></a>
            </td> -->
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;line-height:1.5;"><tbody>
    </tr>
  </tbody></table>


  <!----------------------------------------------------------------------->
  <!------------------------------ News ------------------------------->
  <!----------------------------------------------------------------------->
  <table style="width:100%;border:0px;border-spacing:0px 35px;border-collapse:separate;margin-right:auto;margin-left:auto;line-height:1.5;"><tbody>
    <br>
    <heading>News</heading>
    <br>
    <table width="100%" align="center" border="0" cellpadding="10">
            <tr>
              <td>
                <li>
                  <strong>Nov 2025: </strong> I passed my qualification exam.
                </li>
                <br>
                <li>
                  <strong>Nov 2025: </strong> Thanks <a href="https://users.cg.tuwien.ac.at/zsolnai/about/">K√°roly Zsolnai-Feh√©r</a> for featuring <a href="https://github.com/NYU-ICL/image-gs">Image-GS</a> on <a href="https://www.youtube.com/watch?v=_WjU5d26Cc4"><span style="color: #e0144c;"> <i class="fab fa-youtube"></i> Two Minute Papers</span></a> and <a href="https://www.linkedin.com/in/shubham-anand-91a10b211/">Shubham Anand</a> for creating a thorough and well-explained tutorial on <a href="https://learnopencv.com/image-gs-image-reconstruction-using-2d-gaussians/"><span style="color: #4cc9f0;"> <i class="fa-solid fa-rocket"></i> LearnOpenCV</span></a>!
                </li>
                <br>
                <li>
                  <strong>Aug 2025: </strong> I presented <a href="https://dl.acm.org/doi/10.1145/3721257.3734027">Nano-3D</a> E-Tech demo at SIGGRAPH 2025 in Vancouver.
                </li>
                <br>
                <li>
                  <strong>May 2025: </strong> <a href="https://arxiv.org/abs/2407.01866/" target="_blank">Image-GS</a> and <a href="https://dl.acm.org/doi/10.1145/3721257.3734027">Nano-3D</a> were accepted to SIGGRAPH 2025.
                </li>
                <br>
                <li>
                  <strong>August 2024: </strong> I presented <a href="https://tim-1e.github.io/ProxyTracing/">Proxy Tracing</a> at SIGGRAPH 2024 in Denver.
                </li>
              </td>
            </tr>
          </table>
          <br>

  

  <!----------------------------------------------------------------------->
  <!------------------------------ Research ------------------------------->
  <!----------------------------------------------------------------------->
  <table style="width:100%;border:0px;border-spacing:0px 35px;border-collapse:separate;margin-right:auto;margin-left:auto;line-height:1.5;"><tbody>
    <br>
    <heading>Research</heading>
    <br>
		* denotes equal contributions.
    
  <!----------------------------------------------------------------------->
  <!------------------------------- Physically Grounded Monocular Depth -------------------------------->
  <!----------------------------------------------------------------------->
  <tr>
    <td style="width:42%; text-align:left; padding:0;">
      <img src='images/physically_grounded.png' width="320" height="145" style="display:block;margin-left:-15px;">
    </td>
    <td style="width:60%;background-color:#ffffff">
      <a href="https://arxiv.org/abs/2503.15770" target="_blank">
        <papertitle>
          Physically Grounded Monocular Depth via Nanophotonic Wavefront Prompting
        </papertitle>
      </a>
      <br>
      <strong>Bingxuan Li*</strong>,
      Jiahao Wu*, Yuan Xu*, Zezheng Zhu, 
      <a class="a2" href="https://yunxiangzhang.github.io/" target="_blank">Yunxiang Zhang</a>,
      <a class="a2" href="https://kenchen10.github.io/" target="_blank">Kenneth Chen</a>,
      Yanqi Liang,
      <a class="a2" href="https://www.apam.columbia.edu/faculty/nanfang-yu" target="_blank">Nanfang Yu<span>&#8224;</span></a>,
      <a class="a2" href="https://qisun.me" target="_blank">Qi Sun<span>&#8224;</span></a>
      <br>
      <a href="https://arxiv.org/abs/2503.15770">Paper</a>
      <br>
      <em><strong>ArXiv preprint</strong></em>
      
      <br>
      <p>
        We introduce a nanophotonic metalens that physically encodes metric depth into a single monocular image and enables depth foundation models to recover accurate scale through lightweight prompting and fine-tuning.
      </p>
    </td>
  </tr>

  
  <!----------------------------------------------------------------------->
  <!------------------------------- Nano3d -------------------------------->
  <!----------------------------------------------------------------------->
  <tr>
    <td style="width:42%">
      <img src='images/nano3d.jpg' width="280" height="220">
    </td>
    <td style="width:60%;background-color:#ffffff">
      <a href="https://dl.acm.org/doi/10.1145/3721257.3734027" target="_blank">
        <papertitle>
          Nano-Optics for Depth Sensing
        </papertitle>
      </a>
      <br>
      Yuan Xu*, 
      <strong>Bingxuan Li*</strong>,
      Jiahao Wu*, 
      <a class="a2" href="https://yunxiangzhang.github.io/" target="_blank">Yunxiang Zhang</a>,
      Zezheng Zhu, 
      <a class="a2" href="https://www.apam.columbia.edu/faculty/nanfang-yu" target="_blank">Nanfang Yu</a>,
      <a class="a2" href="https://qisun.me" target="_blank">Qi Sun<span>&#8224;</span></a>
      <br>
      <a href="https://dl.acm.org/doi/10.1145/3721257.3734027">Paper</a>
      <br>
      <em><strong>SIGGRAPH 2025 Emerging Technologies</strong></em>
      
      <br>
      <p>
        We built a metasurface-based depth camera and a neural decoder for accurate monocular metric depth estimation. The system was demonstrated at SIGGRAPH 2025.
      </p>
    </td>
  </tr>
  
  <!----------------------------------------------------------------------->
  <!------------------------------ Image-GS ------------------------------->
  <!----------------------------------------------------------------------->
  <tr>
    <td style="width:42%;padding:.75%;">
      <img src='images/image-gs.jpg' width="270" height="260">
    </td>
    <td style="width:60%;background-color:#ffffff">
      <a href="https://arxiv.org/abs/2407.01866/" target="_blank">
        <papertitle>
          Image-GS: Content-Adaptive Image Representation via 2D Gaussians
        </papertitle>
      </a>
      <br>
      <a class="a2" href="https://yunxiangzhang.github.io/" target="_blank">Yunxiang Zhang*</a>,
      <strong>Bingxuan Li*</strong>,
      <a class="a2" href="https://www.alexku.me/" target="_blank">Alexandr Kuznetsov</a>,
      <a class="a2" href="https://www.akshayjindal.com/" target="_blank">Akshay Jindal</a>,
      <a class="a2" href="https://www.sdiolatz.info/" target="_blank">Stavros Diolatzis</a>,
      <a class="a2" href="https://kenchen10.github.io" target="_blank">Kenneth Chen</a>.
      <a class="a2" href="https://www.intel.com/content/www/us/en/developer/articles/community/gpu-researchers-anton-sochenov.html" target="_blank">Anton Sochenov</a>,
      <a class="a2" href="http://kaplanyan.com/" target="_blank">Anton Kaplanyan</a>,
      <a class="a2" href="https://qisun.me" target="_blank">Qi Sun<span>&#8224;</span></a>
      <br>
      <a href="https://arxiv.org/abs/2407.01866/">Paper</a> /
      <a href="https://kenchen10.github.io/projects/imggs/index.html" target="_blank">Project</a> /
      <a href="https://github.com/NYU-ICL/image-gs">Code</a>
      <br>
      <em><strong>SIGGRAPH 2025</strong></em>
      <br> 
      <p>
        We present Image-GS, a content-adaptive neural image representation using anisotropic 2D Gaussians, offering high memory efficiency, fast random access, and flexible fidelity control for real-time graphics.
      </p>
    </td>
  </tr>
  
  <!----------------------------------------------------------------------->
  <!--------------------------- Proxy-Tracing ----------------------------->
  <!--------------- https://tim-1e.github.io/ProxyTracing/ ---------------->
  <!----------------------------------------------------------------------->
  <tr>
    <td style="width:42%">
      <img src='images/proxy-tracing.png' width="280" height="200">
    </td>
    <td style="width:60%;background-color:#ffffff">
      <a href="https://tim-1e.github.io/ProxyTracing/" target="_blank">
        <papertitle>
          Proxy Tracing: Unbiased Reciprocal Estimation for Optimized Sampling in BDPT
        </papertitle>
      </a>
      <br>
      Fujia Su*,
      <strong>Bingxuan Li*</strong>,
      Qingyang Yin,
      Yanchen Zhang,
      <a class="a2" href="https://lishengpku.github.io/" target="_blank">Sheng Li<span>&#8224;</span></a>
      <br>
      <a href="https://tim-1e.github.io/ProxyTracing/Paper.pdf" target="_blank">Paper</a> /
      <a href="https://tim-1e.github.io/ProxyTracing/" target="_blank">Project</a> / 
      <a href="https://github.com/ssufujia/SPCBPT-OptiX7/tree/DropOutTracing" target="_blank">Code</a> /
      <a href="https://tim-1e.github.io/ProxyTracing/video.mp4" target="_blank">Video</a>
      <br>
      <em><strong>ACM Transactions on Graphics (SIGGRAPH 2024)</strong></em>
      <p> 
        We propose a novel sampling method to handle challenging specular/glossy paths in bidirectional path tracing (BDPT), significantly improving rendering efficiency while ensuring unbiasedness.
      </p>
    </td>
  </tr>
  

  
  <!----------------------------------------------------------------------->
  <!------------------------------ Projects ------------------------------->
  <!----------------------------------------------------------------------->
  <table style="width:100%;border:0px;border-spacing:0px 35px;border-collapse:separate;margin-right:auto;margin-left:auto;line-height:1.5;"><tbody>
    <br>
    <heading>Selected Projects</heading>
    <br>

    <tr>
      <td style="width:42%">
        <img src='images/water.png' width="250">
      </td>
      <td style="width:60%;vertical-align:middle">
          <a href="https://github.com/bingxuan-li/EasyRender" target="_blank">
            <papertitle>EasyRender&nbsp;</papertitle> <img src="icons/github-icon.png" alt="Github" width="14" height="14">
          </a>
          <p> 
            We present EasyRender, a scalable, high-performance 
            ray tracing renderer built upon OptiX 8.0, featuring modular architecture,
            support for pbrt-v3 scenes and Disney Principled Materials, 
            and implementations of advanced physically based rendering algorithms.
          </p>
      </td>
    </tr>

    <tr>
      <td style="width:42%">
          <img src='images/ROMA.png' width="250">
      </td>
      <td style="width:50%">
        <a href="https://github.com/Potato256/my-mitsuba" target="_blank">
          <papertitle>ROMA on Mitsuba&nbsp;</papertitle> <img src="icons/github-icon.png" alt="Github" width="14" height="14">
        </a>
        <p> 
          This project explores the further applications of 
            <a href="https://zheng95z.github.io/publications/roma23">ROMA</a>
          in rendering, implemented on Mitsuba 0.6. 
          We primarily focused on enhancing the performance of ray tracing using ROMA, a novel acceleration method.
        </p>
      </td>
    </tr>

  <!-- Services -->

  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;line-height:1.5;"><tbody>
    <br>
      <heading>Services</heading>
    <br>
    <td style="padding:10px;width:30%;vertical-align:middle">
      <p style="font-size: 15px;">
        <strong>Reviewer</strong>: SIGGRAPH Asia, TVCG</strong>     
    

    </td></tr>
  </tbody></table>


  <!-- Miscellaneous -->

  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;line-height:1.5;"><tbody>
    <br>
      <heading>About Me</heading>
    <br>
    <td style="padding:10px;width:30%;vertical-align:middle">
      <p style="font-size: 15px;">
        I enjoy reading, gaming, photography and other nerdy stuffs outside of work.     
        </td></tr>
  </tbody></table>
  
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr>
      <td style="text-align:center">
      <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=000000&w=a&t=tt&d=NeZzG10WdpN8qzKkIbSsdvul2fS8zmGQF4mQ3TPy4wY&co=ffffff&ct=5b5858'></script>
    </td>
    </tr>
  </table>
  <!-- Aknowledgements -->
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
      <hr>
        <p style="text-align:center">
          This homepage is designed based on 
            <a href="https://jonbarron.info/">Jon Barron</a>
          's website and deployed on <a href="https://pages.github.com/">Github Pages</a>. Last updated: Jan. 1, 2026        
          <br>
          ¬© 2025 Bingxuan Li
        </p>
      </td>
      </tr>
  </tbody></table>
 
</body>
</html>
